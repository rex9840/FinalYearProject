# -*- coding: utf-8 -*-
"""Recomendation_using_clusters_withdbdata

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14iDq-SJz85zKzcCtoLoAFwBbaL1N0GOx
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files
import seaborn
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D

file = files.upload()

resources = pd.read_csv("_Resources__202403062247.csv")
resources_tag = pd.read_csv("_Resources_tags__202403062248.csv")
tags = pd.read_csv("_Tags__202403062248.csv")
user_rating= pd.read_csv("_UserResourceInteraction__202403062248.csv")
users = pd.read_csv("users_202403062248.csv")
user_tag_slice = pd.read_csv("user_resources.csv")

resources.head()

tags.head()

resources_tag.head()

user_rating.head()

users.head()

user_tag_slice = pd.read_csv("user_resources.csv")

user_tag_slice.head()

user_tag_slice.columns.tolist()

# prompt: rename column resource_id.1 into resource_id

user_tag_slice = user_tag_slice.drop(columns=["Unnamed: 0","resource_id"])
user_tag_slice







columns = user_tag_slice .columns.tolist()

columns.remove("rating")
columns.remove('user_id')

for column in columns:
  print(column)
  user_tag_slice[column] = user_tag_slice[column].mul(user_tag_slice["rating"],axis=0)

user_tag_slice.head()



user_tag_slice = user_tag_slice.groupby(by="user_id").mean()
user_tag_slice = user_tag_slice.fillna(value=0)
user_tag_slice.head()

for column in user_tag_slice.columns:
    unique_values = user_tag_slice[column].value_counts()
    print(f"values count in {column}:")
    print(unique_values)
    print()

###########################################################


# K-MEAN CLUSTURING

# Elbow Method  for determination of clusters

# poting against sumofsquare(inertia) vs number of clusters

inertia = []

for k in range(1,9):
  k_means  = KMeans(n_clusters=k,n_init=10,random_state=42)
  k_means.fit(user_tag_slice)
  inertia.append(k_means.inertia_)

plt.plot(range(1,9), inertia, marker= 'o' )
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal k')
plt.grid(True)
plt.show()

kmeans = KMeans(n_clusters=4,n_init=10,random_state=42)
users_with_label = pd.DataFrame(user_tag_slice)
users_with_label["label"]=kmeans.fit_predict(user_tag_slice)
users_with_label

# prompt: can you generate me the visualization for the cluster

pca = PCA(n_components=3)
pca_data = pca.fit_transform(user_tag_slice)

fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

for i in range(kmeans.n_clusters):
  ax.scatter(pca_data[users_with_label["label"] == i, 0],
            pca_data[users_with_label["label"] == i, 1],
            pca_data[users_with_label["label"] == i, 2],
            s=50, label=f"Cluster {i+1}")

ax.set_xlabel('PC1')
ax.set_ylabel('PC2')
ax.set_zlabel('PC3')
ax.set_title('3D Visualization of Clusters')
ax.legend()

plt.show()



user_rating.head()



# Recomendations

rating_user = user_rating.join(users_with_label['label'], on ="user_id")
rating_user.head()



print(rating_user)

print(rating_user.columns.tolist())

group = rating_user[['resource_id','rating','label']].groupby(by=["label","resource_id"])["rating"].agg(["mean","count"])

group.head()

# goodness evaluation (obj -> objective) is the mean rating multiplied by the count


group["obj"] = group["mean"]*group["count"]

group.head()

group_obj = group[["obj"]].dropna()

group_obj.head()

# Assuming user_id is the input mechanism
user_id = 2
# Filter user data
user_data = rating_user[rating_user["user_id"] == user_id]
print(user_data)
user_cluster_label = user_data["label"].iloc[0]
print(user_data["label"].iloc[0])


# Get recommendations for the user's cluster
user_group_obj = group_obj.loc[user_cluster_label]
sorted_recommendations = user_group_obj.sort_values(by="obj", ascending=False).reset_index()

# Join with course details
recommendations = sorted_recommendations.join(resources[['name', 'resource_id']].set_index('resource_id'), on="resource_id")
print(recommendations.head(50))

# Display recommendations
print(f"Top recommendations for user {user_id}:")
for i, row in recommendations.iterrows():
    print(f"- {row['name']}")





resources.head(1)



# sorting information



lebels  = group_obj.index.get_level_values(0).unique().tolist()
print(lebels)


recomendation = []

for x in lebels:

  sort = group_obj.loc[x].sort_values(by="obj", ascending=False).reset_index()
  join_ = sort.join(
      resources[['name', 'resource_id']].set_index('resource_id'), on="resource_id"

  )

  recomendation.append(join_['name'].rename(x))

recomendation_= pd.concat(recomendation ,axis =1)

recomendation_.head(20)



recomendation_.head()

print(recomendation_.head(2).to_numpy())

print(np.unique(recomendation_.head(2).to_numpy()))

for i in range(4):
  print(np.unique(recomendation_.head(i).to_numpy()))

for i in range(7):
    print(f'{i} recomendations: {np.unique(recomendation_.head(i).to_numpy()).__len__()} resources in total')

recomendation_.loc(1)[0]